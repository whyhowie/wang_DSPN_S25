{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2W919d2ZXp7"
      },
      "source": [
        "# Exercise 10: Mixed effects"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading and formatting the data 1/1\n",
        "2. Model fitting 3/4: the interaction term is missing\n",
        "3. Model assessment 4/4\n",
        "4. Reflection 1/1"
      ],
      "metadata": {
        "id": "NauAweHjpxa2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nOzVhyZXqK"
      },
      "source": [
        "This homework assignment is designed to give you practice fitting and interpreting mixed effects models.\n",
        "\n",
        "We will be using the **LexicalData.csv** and **Items.csv** files from the *Homework/lexDat* folder in the class GitHub repository again.\n",
        "\n",
        "This data is a subset of the [English Lexicon Project database](https://elexicon.wustl.edu/). It provides the reaction times (in milliseconds) of many subjects as they are presented with letter strings and asked to decide, as quickly and as accurately as possible, whether the letter string is a word or not. The **Items.csv** provides characteristics of the words used, namely frequency (how common is this word?) and length (how many letters?). Unlike in the previous homework, there isn't any missing data in the **LexicalData.csv** file.\n",
        "\n",
        "*Data courtesy of Balota, D.A., Yap, M.J., Cortese, M.J., Hutchison, K.A., Kessler, B., Loftis, B., Neely, J.H., Nelson, D.L., Simpson, G.B., & Treiman, R. (2007). The English Lexicon Project. Behavior Research Methods, 39, 445-459.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DsyBTB6ZXqN"
      },
      "source": [
        "---\n",
        "## 1. Loading and formatting the data (1 point)\n",
        "\n",
        "Load in data from the **LexicalData.csv** and **Items.csv** files. As in the previous homeworks, remove the commas from the reaction times and convert them from strings to numbers. Use `left_join` to add word characteristics `Length` and `Log_Freq_Hal` from **Items** to **LexicalData**.\n",
        "\n",
        "*Note: the `Freq_HAL` variable in **Items.csv** has a similar formatting issue, using string values with commas. We're not going to worry about fixing this since we're only using `Log_Freq_HAL`, which is the natural log transformation of `Freq_HAL`, in this homework.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnBVazYfZXqP",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "6fc38e58-0c10-47b4-e3e3-d254637186a2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 6 × 11</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>X</th><th scope=col>Sub_ID</th><th scope=col>Trial</th><th scope=col>Type</th><th scope=col>D_RT</th><th scope=col>D_Word</th><th scope=col>Outlier</th><th scope=col>D_Zscore</th><th scope=col>Correct</th><th scope=col>Length</th><th scope=col>Log_Freq_HAL</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>1</th><td>1</td><td>157</td><td>1</td><td>1</td><td> 710</td><td>browse     </td><td>false</td><td>-0.437</td><td>1</td><td> 6</td><td>8.856</td></tr>\n",
              "\t<tr><th scope=row>2</th><td>2</td><td> 67</td><td>1</td><td>1</td><td>1094</td><td>refrigerant</td><td>false</td><td> 0.825</td><td>1</td><td>11</td><td>4.644</td></tr>\n",
              "\t<tr><th scope=row>3</th><td>3</td><td>120</td><td>1</td><td>1</td><td> 587</td><td>gaining    </td><td>false</td><td>-0.645</td><td>1</td><td> 7</td><td>8.304</td></tr>\n",
              "\t<tr><th scope=row>4</th><td>4</td><td> 21</td><td>1</td><td>1</td><td> 984</td><td>cheerless  </td><td>false</td><td> 0.025</td><td>1</td><td> 9</td><td>2.639</td></tr>\n",
              "\t<tr><th scope=row>5</th><td>5</td><td>236</td><td>1</td><td>1</td><td> 577</td><td>pattered   </td><td>false</td><td>-0.763</td><td>1</td><td> 8</td><td>1.386</td></tr>\n",
              "\t<tr><th scope=row>6</th><td>6</td><td>236</td><td>2</td><td>1</td><td> 715</td><td>conjures   </td><td>false</td><td>-0.364</td><td>1</td><td> 8</td><td>5.268</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 6 × 11\n",
              "\\begin{tabular}{r|lllllllllll}\n",
              "  & X & Sub\\_ID & Trial & Type & D\\_RT & D\\_Word & Outlier & D\\_Zscore & Correct & Length & Log\\_Freq\\_HAL\\\\\n",
              "  & <int> & <int> & <int> & <int> & <dbl> & <chr> & <chr> & <dbl> & <int> & <int> & <dbl>\\\\\n",
              "\\hline\n",
              "\t1 & 1 & 157 & 1 & 1 &  710 & browse      & false & -0.437 & 1 &  6 & 8.856\\\\\n",
              "\t2 & 2 &  67 & 1 & 1 & 1094 & refrigerant & false &  0.825 & 1 & 11 & 4.644\\\\\n",
              "\t3 & 3 & 120 & 1 & 1 &  587 & gaining     & false & -0.645 & 1 &  7 & 8.304\\\\\n",
              "\t4 & 4 &  21 & 1 & 1 &  984 & cheerless   & false &  0.025 & 1 &  9 & 2.639\\\\\n",
              "\t5 & 5 & 236 & 1 & 1 &  577 & pattered    & false & -0.763 & 1 &  8 & 1.386\\\\\n",
              "\t6 & 6 & 236 & 2 & 1 &  715 & conjures    & false & -0.364 & 1 &  8 & 5.268\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 6 × 11\n",
              "\n",
              "| <!--/--> | X &lt;int&gt; | Sub_ID &lt;int&gt; | Trial &lt;int&gt; | Type &lt;int&gt; | D_RT &lt;dbl&gt; | D_Word &lt;chr&gt; | Outlier &lt;chr&gt; | D_Zscore &lt;dbl&gt; | Correct &lt;int&gt; | Length &lt;int&gt; | Log_Freq_HAL &lt;dbl&gt; |\n",
              "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
              "| 1 | 1 | 157 | 1 | 1 |  710 | browse      | false | -0.437 | 1 |  6 | 8.856 |\n",
              "| 2 | 2 |  67 | 1 | 1 | 1094 | refrigerant | false |  0.825 | 1 | 11 | 4.644 |\n",
              "| 3 | 3 | 120 | 1 | 1 |  587 | gaining     | false | -0.645 | 1 |  7 | 8.304 |\n",
              "| 4 | 4 |  21 | 1 | 1 |  984 | cheerless   | false |  0.025 | 1 |  9 | 2.639 |\n",
              "| 5 | 5 | 236 | 1 | 1 |  577 | pattered    | false | -0.763 | 1 |  8 | 1.386 |\n",
              "| 6 | 6 | 236 | 2 | 1 |  715 | conjures    | false | -0.364 | 1 |  8 | 5.268 |\n",
              "\n"
            ],
            "text/plain": [
              "  X Sub_ID Trial Type D_RT D_Word      Outlier D_Zscore Correct Length\n",
              "1 1 157    1     1     710 browse      false   -0.437   1        6    \n",
              "2 2  67    1     1    1094 refrigerant false    0.825   1       11    \n",
              "3 3 120    1     1     587 gaining     false   -0.645   1        7    \n",
              "4 4  21    1     1     984 cheerless   false    0.025   1        9    \n",
              "5 5 236    1     1     577 pattered    false   -0.763   1        8    \n",
              "6 6 236    2     1     715 conjures    false   -0.364   1        8    \n",
              "  Log_Freq_HAL\n",
              "1 8.856       \n",
              "2 4.644       \n",
              "3 8.304       \n",
              "4 2.639       \n",
              "5 1.386       \n",
              "6 5.268       "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "# setwd(\"../Homework datasets/lexDat\") # Uncomment this when running for the first time\n",
        "library(tidyverse)\n",
        "\n",
        "lex <- read.csv('LexicalData_withIncorrect.csv')\n",
        "item <- read.csv('Items.csv')\n",
        "\n",
        "lex |> left_join(item[c('Length', 'Log_Freq_HAL', 'Word')],\n",
        "\tby = join_by(D_Word == Word)) |>\n",
        "\tdrop_na() ->\n",
        "\tlex\n",
        "\n",
        "lex$D_RT <- as.numeric(gsub(\",\", \"\", lex$D_RT)) # also fix the commas\n",
        "head(lex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXy81Viishk1"
      },
      "source": [
        "---\n",
        "## 2. Model fitting (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7_gEgkbzFtU"
      },
      "source": [
        "First, fit a linear model with `Log_Freq_HAL` and `Length` as predictors, and `D_RT` as the output. Include an interaction term. Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIOIg-GRz4rN",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "8f06eb26-0886-49e0-a65f-709139dd530f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\n",
              "Call:\n",
              "glm(formula = D_RT ~ Length + Log_Freq_HAL, data = lex)\n",
              "\n",
              "Coefficients:\n",
              "             Estimate Std. Error t value Pr(>|t|)    \n",
              "(Intercept)  786.1944     7.6927  102.20   <2e-16 ***\n",
              "Length        29.0685     0.6311   46.06   <2e-16 ***\n",
              "Log_Freq_HAL -30.8857     0.6559  -47.09   <2e-16 ***\n",
              "---\n",
              "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
              "\n",
              "(Dispersion parameter for gaussian family taken to be 147907.1)\n",
              "\n",
              "    Null deviance: 1.1435e+10  on 70588  degrees of freedom\n",
              "Residual deviance: 1.0440e+10  on 70586  degrees of freedom\n",
              "AIC: 1040643\n",
              "\n",
              "Number of Fisher Scoring iterations: 2\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "lm.fit = glm(D_RT ~ Length+Log_Freq_HAL, data=lex)\n",
        "\n",
        "summary(lm.fit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbeg_JrS3mwU"
      },
      "source": [
        "Now, install `lme4` using `install.packages()` and then load the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFSnvvb_re2O",
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "# install.packages(\"lme4\")\t# run this once\n",
        "library(lme4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZJns7xr41nW"
      },
      "source": [
        "Now fit a mixed effects model that includes the same predictors as the linear model above, as well as random intercepts for `Sub_ID` (i.e., cases where subject ID shifts the RT mean). Use `summary()` to look at the model output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kjwT0je57N7",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "388ac118-b1e5-4660-aed5-7c683d1b98b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear mixed model fit by REML ['lmerMod']\n",
              "Formula: D_RT ~ Length + Log_Freq_HAL + (1 | Sub_ID)\n",
              "   Data: lex\n",
              "\n",
              "REML criterion at convergence: 1012480\n",
              "\n",
              "Scaled residuals: \n",
              "    Min      1Q  Median      3Q     Max \n",
              "-4.2412 -0.5450 -0.1601  0.3038 11.0720 \n",
              "\n",
              "Random effects:\n",
              " Groups   Name        Variance Std.Dev.\n",
              " Sub_ID   (Intercept) 51073    226.0   \n",
              " Residual             97260    311.9   \n",
              "Number of obs: 70589, groups:  Sub_ID, 299\n",
              "\n",
              "Fixed effects:\n",
              "             Estimate Std. Error t value\n",
              "(Intercept)  785.3529    14.4874   54.21\n",
              "Length        29.6056     0.5127   57.75\n",
              "Log_Freq_HAL -31.3619     0.5331  -58.83\n",
              "\n",
              "Correlation of Fixed Effects:\n",
              "            (Intr) Length\n",
              "Length      -0.365       \n",
              "Log_Frq_HAL -0.331  0.355"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "# Random intercepts only\n",
        "me.fit = lmer(D_RT ~ Length+Log_Freq_HAL + (1 | Sub_ID), data=lex)\n",
        "\n",
        "summary(me.fit)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfb_ovk7JFGt"
      },
      "source": [
        "---\n",
        "## 3. Model assessment (4 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7B1Ux6RHGjy"
      },
      "source": [
        "Compare the three t-values for the fixed effects and the mixed effects models. How do they differ, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCi5gYOeHo6m"
      },
      "source": [
        "> *Write your response here*\n",
        ">\n",
        "> The absolute values of t-values in the mixed effect model are larger compared to the fixed effects model (57.75 vs 46.06 for `Length`; -58.83 vs -47.09 for `Log_Freq_HAL`). Thus, we can say that isolating the random effect made the predicted relationship stronger."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hukKG1AbGqXM"
      },
      "source": [
        "Use the Akaike Information Criterion (AIC) to compare these two models. Which one is better?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMDg8qb5FhJz",
        "vscode": {
          "languageId": "r"
        },
        "outputId": "9940b736-a715-4214-9bf8-cd37f6fd99b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A data.frame: 2 × 2</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>df</th><th scope=col>AIC</th></tr>\n",
              "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>lm.fit</th><td>4</td><td>1040643</td></tr>\n",
              "\t<tr><th scope=row>me.fit</th><td>5</td><td>1012490</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/latex": [
              "A data.frame: 2 × 2\n",
              "\\begin{tabular}{r|ll}\n",
              "  & df & AIC\\\\\n",
              "  & <dbl> & <dbl>\\\\\n",
              "\\hline\n",
              "\tlm.fit & 4 & 1040643\\\\\n",
              "\tme.fit & 5 & 1012490\\\\\n",
              "\\end{tabular}\n"
            ],
            "text/markdown": [
              "\n",
              "A data.frame: 2 × 2\n",
              "\n",
              "| <!--/--> | df &lt;dbl&gt; | AIC &lt;dbl&gt; |\n",
              "|---|---|---|\n",
              "| lm.fit | 4 | 1040643 |\n",
              "| me.fit | 5 | 1012490 |\n",
              "\n"
            ],
            "text/plain": [
              "       df AIC    \n",
              "lm.fit 4  1040643\n",
              "me.fit 5  1012490"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "-28153.3912642527"
            ],
            "text/latex": [
              "-28153.3912642527"
            ],
            "text/markdown": [
              "-28153.3912642527"
            ],
            "text/plain": [
              "[1] -28153.39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "# We will compare the two models using the Akaike information criterion (AIC)\n",
        "ic = AIC(lm.fit, me.fit)\n",
        "ic\n",
        "diff(ic$AIC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4oTfsYmIvYt"
      },
      "source": [
        "> *Write your response here*\n",
        ">\n",
        "> `me.fit` has the lower AIC, which means that it has a better fit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARF2PF2yLXkZ"
      },
      "source": [
        "---\n",
        "##  4. Reflection (1 point)\n",
        "\n",
        "What other random effects could be controlled for in this data set?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "r"
        },
        "id": "zulKyOqypwuJ"
      },
      "source": [
        "> *Write your response here*\n",
        ">\n",
        "> It appears the the `Trial` number can be regarded as a random effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4MPECMmZXqe"
      },
      "source": [
        "**DUE:** 5pm EST, March 18, 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GUofXN4BVy"
      },
      "source": [
        "**IMPORTANT** Did you collaborate with anyone on this assignment? If so, list their names here.\n",
        "> *Someone's Name*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.4.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}